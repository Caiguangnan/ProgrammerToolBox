### 一、描述性统计

#### 1.1 NumPy中的描述性统计函数 

pandas库基于NumPy，自然也可以用这些函数对数据框进行描述性统计。

| 函数    | 说明                   |
| ------- | ---------------------- |
| sum     | 计算数组的和           |
| mean    | 计算数组均值           |
| std     | 计算数组标准差         |
| var     | 计算数组方差           |
| min     | 计算数组最小值         |
| max     | 计算数组最大值         |
| argmin  | 返回数组最小元素的索引 |
| argmax  | 返回数组最大元素的索引 |
| cumsum  | 计算所有元素的累计和   |
| cumprod | 计算所有元素的累计积   |

说明：当axis=0时，表示沿着纵轴计算。当axis=1时，表示沿着横轴计算。默认时计算一个总值。

#### 1.2 **pandas**描述性统计方法

- 计算均值，detail['amounts'].mean()。。。其他的类似
- pandas还提供了一个方法叫作describe，能够一次性得出数据框所有数值型特征的非空值数目、均值、四分位数、标准差。
- 描述类别型特征的分布状况，可以使用频数统计表。pandas库中实现频数统计的方法为value_counts
- pandas提供了categories类，可以使用astype方法将目标特征的数据类型转换为category类别
- describe方法，还能够支持对category类型的数据进行描述性统计，四个统计量分别为列非空元素的数目，类别的数目，数目最多的类别，数目最多类别的数目。

![image-20200308161758078](https://gitee.com/cgntiger/blogImage/raw/master/img/20200331234729.png)

```python
data2.mean() #求对列，均值。类似的还有 data2.min()等等
data2.describe() #一次性得出所有数据型特征
data['dishes_name'].value_counts() #频数统计
data['dishes_name'].astype('category') #转换成category类别
data['dishes_name'].astype('category').describe() #转换成category类别，进行描述性统计
```

### 二、分组聚合（组内计算）

#### 2.1 groupby方法

语法：*DataFrame.***groupby***(by=None, axis=0, level=None,* *as_index**=True, sort=True,* *group_keys**=True, squeeze=False, ****kwargs**)*

![image-20200308165626483](https://gitee.com/cgntiger/blogImage/raw/master/img/20200331234730.png)

- 结果并不能直接查看，而是被存在内存中，输出的是内存地址。实际上分组后的数据对象GroupBy类似Series与DataFrame，是pandas提供的一种对象。GroupBy对象常用的描述性统计方法如下。

![image-20200308170528250](https://gitee.com/cgntiger/blogImage/raw/master/img/20200331234731.png)

```python
data[['order_id', 'counts', 'amounts']].groupby(by='order_id') #根据order_id进行分组
```

#### 2.2 agg和aggregate函数(常用agg)

语法：

-  *DataFrame.***agg***(**func**, axis=0, ***args**, ****kwargs**)*
- *DataFrame.***aggregate***(**func**, axis=0, ***args**, ****kwargs**)*

![image-20200308170737213](https://gitee.com/cgntiger/blogImage/raw/master/img/20200331234732.png)

```python
import numpy as np
data[[ 'counts', 'amounts']].agg(np.sum) #对所选列，进行求和
data[[ 'counts', 'amounts']].agg([np.sum, np.mean])
data[[ 'counts', 'amounts']].agg({'counts':np.sum, 'amounts':[np.sum, np.mean]})
data_gb.agg({'counts':np.sum, 'amounts':[np.sum, np.mean]}) #针对对应列求统计量
```

#### 2.3 apply方法

语法：*DataFrame.***apply***(**func**, axis=0, broadcast=False, raw=False, reduce=None,* *args**=(), ****kwds**)*

![image-20200308171501182](https://gitee.com/cgntiger/blogImage/raw/master/img/20200331234733.png)

```python
data[[ 'counts', 'amounts']].apply(np.sum)
```

#### 2.4 transform方法

- transform方法能够对整个DataFrame的所有元素进行操作。且transform方法只有一个参数“func”，表示对DataFrame操作的函数。
- 同时transform方法还能够对DataFrame分组后的对象GroupBy进行操作，可以实现组内离差标准化等操作。

```python
print(data[[ 'counts', 'amounts']].transform(lambda x: x**2).head())
data_gb.transform(lambda x: (x.mean() - x.min())/(x.max() - x.min()))
```

说明：若在计算离差标准化的时候结果中有NaN，这是由于根据离差标准化公式，最大值和最小值相同的情况下分母是0。而分母为0的数在Python中表示为NaN。